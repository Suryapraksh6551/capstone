{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Capstone Project(Data Engineering)\n",
    "\n",
    "#### Project Summary and outline\n",
    "This project aims to be able to answers questions on US immigration trend\n",
    "1. Most popular cities\n",
    "2. Gender distribution of the immigration\n",
    "3. visa type distribution\n",
    "4. average age per immigrant \n",
    "5. average temperature per month per city\n",
    "\n",
    "Data taken from three different sources \n",
    "1. I94 immigration dataset of 2016\n",
    "2. City temperature\n",
    "3. US city demographic data from openshoft\n",
    "\n",
    "Design 4 dimention tables and 1 fact table\n",
    "cities, immigrants, monthl average city temp and time, and immigration\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "#!pip install pyspark\n",
    "from pyspark.sql  import SparkSession\n",
    "\n",
    "import psycopg2\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob \n",
    "import cleanup as cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "The goal of this project is pull data from 3 different sources and create fact, dimention table to analyze US immigration using city demographisc, seasions, avg temperature.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "\n",
    "I94 Immigration Data: This data comes from the U.S. National Tourism and Trade Office and contains various statistics on international visitor arrival in USA.\n",
    "World Temperature Data: This data comes from Kaggle and contains average weather temperatures by city. \n",
    "U.S. City Demographic Data: comes from OpenSoft and contains information about the demographics of all US cities such as average age, male and female population. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Load data from CSV file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Follow below steps and repeat step 2, 3  to load Airport Codes,Immigration, US  Cities Demographic\n",
    "1. Creat Spark Session(Set app name to Capstone)\n",
    "2. Read Csv File\n",
    "3. Show data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create pyspark session\n",
    "pySparkSession = SparkSession.builder.\\\n",
    "config(\"spark.jars.repositories\", \"https://repos.spark-packages.org/\").\\\n",
    "config(\"spark.jars.packages\", \"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "enableHiveSupport().getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Load airports information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>None</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>None</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>None</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>None</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport           11   \n",
       "1  00AA  small_airport                Aero B Ranch Airport         3435   \n",
       "2  00AK  small_airport                        Lowell Field          450   \n",
       "3  00AL  small_airport                        Epps Airpark          820   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport          237   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0        NA          US      US-PA      Bensalem      00A      None   \n",
       "1        NA          US      US-KS         Leoti     00AA      None   \n",
       "2        NA          US      US-AK  Anchor Point     00AK      None   \n",
       "3        NA          US      US-AL       Harvest     00AL      None   \n",
       "4        NA          US      US-AR       Newport     None      None   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4       None                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load airport codes data \n",
    "airports_info_df = pySparkSession.read.csv(\"csv/airport-codes_csv.csv\",header=True)\n",
    "airports_info_df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, ident: string, type: string, name: string, elevation_ft: string, continent: string, iso_country: string, iso_region: string, municipality: string, gps_code: string, iata_code: string, local_code: string, coordinates: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports_info_df.columns\n",
    "airports_info_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>None</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>None</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN    None   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U     None   1979.0  10282016   None   None   \n",
       "1      NaN   ...           Y     None   1991.0       D/S      M   None   \n",
       "2  20691.0   ...        None        M   1961.0  09302016      M   None   \n",
       "3  20567.0   ...        None        M   1988.0  09302016   None   None   \n",
       "4  20567.0   ...        None        M   2012.0  09302016   None   None   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0    None  1.897628e+09   None       B2  \n",
       "1    None  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load immigration data through sas7bat files\n",
    "# This project only the i94_apr16_sub.sas7bdat will be used for this project, inorder to avoid memory errors\n",
    "i94_all_files = glob.glob(\"../../data/18-83510-I94-Data-2016/*.sas7bdat\")\n",
    "i94_fname = \"../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat\"\n",
    "i94_df = pySparkSession.read.format(\"com.github.saurfang.sas.spark\").load(i94_fname)\n",
    "i94_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert data formates, It will be easy for query\n",
    "convert_isoformat = udf(lambda x: (datetime(1960, 1, 1).date() + timedelta(x)).isoformat() if x else None)\n",
    "valid_birth_year = udf(lambda yr: yr if (yr and 1900 <= yr <= 2016) else None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_df =  i94_df \\\n",
    "          .withColumn('arrdate', convert_isoformat(i94_df.arrdate)) \\\n",
    "          .withColumn('depdate', convert_isoformat(i94_df.depdate)) \\\n",
    "          .withColumn(\"biryear\", valid_birth_year(i94_df.biryear)) \\\n",
    "          .dropDuplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_df.createOrReplaceTempView('staging_i94')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Us cities demographics\n",
    "Contains information about city demographics data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics_df = pySparkSession.read.csv(\"csv/us-cities-demographics.csv\",inferSchema=True, header=True, sep=';')\n",
    "demographics_df.toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, City: string, State: string, Median Age: string, Male Population: string, Female Population: string, Total Population: string, Number of Veterans: string, Foreign-born: string, Average Household Size: string, State Code: string, Race: string, Count: string]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['City',\n",
       " 'State',\n",
       " 'Median Age',\n",
       " 'Male Population',\n",
       " 'Female Population',\n",
       " 'Total Population',\n",
       " 'Number of Veterans',\n",
       " 'Foreign-born',\n",
       " 'Average Household Size',\n",
       " 'State Code',\n",
       " 'Race',\n",
       " 'Count']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.737</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1744-04-01</td>\n",
       "      <td>5.788</td>\n",
       "      <td>3.624</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1744-05-01</td>\n",
       "      <td>10.644</td>\n",
       "      <td>1.283</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1744-06-01</td>\n",
       "      <td>14.051</td>\n",
       "      <td>1.347</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1744-07-01</td>\n",
       "      <td>16.082</td>\n",
       "      <td>1.396</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1744-08-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dt  AverageTemperature  AverageTemperatureUncertainty   City  \\\n",
       "0 1743-11-01               6.068                          1.737  Århus   \n",
       "1 1743-12-01                 NaN                            NaN  Århus   \n",
       "2 1744-01-01                 NaN                            NaN  Århus   \n",
       "3 1744-02-01                 NaN                            NaN  Århus   \n",
       "4 1744-03-01                 NaN                            NaN  Århus   \n",
       "5 1744-04-01               5.788                          3.624  Århus   \n",
       "6 1744-05-01              10.644                          1.283  Århus   \n",
       "7 1744-06-01              14.051                          1.347  Århus   \n",
       "8 1744-07-01              16.082                          1.396  Århus   \n",
       "9 1744-08-01                 NaN                            NaN  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  \n",
       "5  Denmark   57.05N    10.33E  \n",
       "6  Denmark   57.05N    10.33E  \n",
       "7  Denmark   57.05N    10.33E  \n",
       "8  Denmark   57.05N    10.33E  \n",
       "9  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Load global temperature\n",
    "path = '../../data2/GlobalLandTemperaturesByCity.csv'\n",
    "temperature_df = pySparkSession.read.csv(path,inferSchema=True, header=True)\n",
    "temperature_df.limit(20).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data \n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Missing values and duplicate data clean up\n",
    "## i94_df , demographics_df and temperature_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping missing data...\n",
      "+------+------+------+------+------+-------+----------+-------+-------+----------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+---------------+-----+--------+\n",
      "|cicid |i94yr |i94mon|i94cit|i94res|i94port|arrdate   |i94mode|i94addr|depdate   |i94bir|i94visa|count|dtadfile|visapost|occup|entdepa|entdepd|entdepu|matflag|biryear|dtaddto |gender|insnum|airline|admnum         |fltno|visatype|\n",
      "+------+------+------+------+------+-------+----------+-------+-------+----------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+---------------+-----+--------+\n",
      "|30.0  |2016.0|4.0   |101.0 |101.0 |ATL    |2016-04-01|1.0    |NJ     |2016-05-04|49.0  |2.0    |1.0  |20160401|TIA     |null |G      |O      |null   |M      |1967.0 |09302016|M     |null  |OS     |9.247020943E10 |00089|B2      |\n",
      "|84.0  |2016.0|4.0   |103.0 |103.0 |BOS    |2016-04-01|1.0    |NH     |2016-04-06|22.0  |1.0    |1.0  |20160401|null    |null |G      |O      |null   |M      |1994.0 |06292016|M     |null  |LH     |5.5453515433E10|00424|WB      |\n",
      "|126.0 |2016.0|4.0   |103.0 |103.0 |NEW    |2016-04-01|1.0    |NJ     |2016-04-24|47.0  |2.0    |1.0  |20160401|null    |null |G      |O      |null   |M      |1969.0 |06292016|F     |null  |OS     |5.5422597133E10|00089|WT      |\n",
      "|166.0 |2016.0|4.0   |103.0 |103.0 |FTL    |2016-04-01|1.0    |FL     |2016-04-09|29.0  |2.0    |1.0  |20160401|null    |null |G      |R      |null   |M      |1987.0 |06292016|M     |null  |DY     |5.5462463033E10|07031|WT      |\n",
      "|386.0 |2016.0|4.0   |103.0 |103.0 |MIA    |2016-04-01|1.0    |FL     |2016-04-11|56.0  |2.0    |1.0  |20160401|null    |null |G      |O      |null   |M      |1960.0 |06292016|F     |null  |OS     |5.5430477833E10|00097|WT      |\n",
      "|608.0 |2016.0|4.0   |103.0 |103.0 |TOR    |2016-04-01|1.0    |TX     |2016-04-08|45.0  |1.0    |1.0  |20160401|null    |null |G      |O      |null   |M      |1971.0 |06292016|M     |null  |RS     |5.5421404633E10|07665|WB      |\n",
      "|702.0 |2016.0|4.0   |103.0 |343.0 |SFR    |2016-04-01|1.0    |CA     |2016-04-11|60.0  |2.0    |1.0  |20160401|null    |null |G      |O      |null   |M      |1956.0 |06292016|M     |null  |LH     |5.5462133033E10|00458|WT      |\n",
      "|1335.0|2016.0|4.0   |104.0 |104.0 |NYC    |2016-04-01|1.0    |NY     |2016-04-06|56.0  |2.0    |1.0  |20160401|null    |null |G      |O      |null   |M      |1960.0 |06292016|M     |null  |SN     |5.5421215833E10|01401|WT      |\n",
      "|1635.0|2016.0|4.0   |104.0 |104.0 |MIA    |2016-04-01|1.0    |FL     |2016-04-09|46.0  |2.0    |1.0  |20160401|null    |null |G      |O      |null   |M      |1970.0 |06292016|F     |null  |UX     |5.5460507833E10|00097|WT      |\n",
      "|1904.0|2016.0|4.0   |104.0 |104.0 |HOU    |2016-04-01|1.0    |NY     |2016-04-02|69.0  |2.0    |1.0  |20160401|BRS     |null |G      |O      |null   |M      |1947.0 |09302016|F     |null  |UA     |9.250629773E10 |05202|B2      |\n",
      "|2867.0|2016.0|4.0   |108.0 |108.0 |BOS    |2016-04-01|1.0    |MA     |2016-04-10|61.0  |1.0    |1.0  |20160401|null    |null |G      |O      |null   |M      |1955.0 |06292016|M     |null  |SK     |5.5435267333E10|00927|WB      |\n",
      "|3061.0|2016.0|4.0   |108.0 |108.0 |WAS    |2016-04-01|1.0    |WA     |2016-04-19|79.0  |2.0    |1.0  |20160401|null    |null |G      |O      |null   |M      |1937.0 |06292016|F     |null  |KL     |5.5441905933E10|00651|WT      |\n",
      "|3202.0|2016.0|4.0   |108.0 |108.0 |NYC    |2016-04-01|1.0    |NY     |2016-04-15|28.0  |2.0    |1.0  |20160401|null    |null |G      |O      |null   |M      |1988.0 |06292016|F     |null  |DY     |5.5463479633E10|07011|WT      |\n",
      "|4271.0|2016.0|4.0   |110.0 |110.0 |SFR    |2016-04-01|1.0    |CA     |2016-04-10|37.0  |1.0    |1.0  |20160401|null    |null |G      |O      |null   |M      |1979.0 |06292016|M     |null  |LH     |5.5433524833E10|00454|WB      |\n",
      "|4820.0|2016.0|4.0   |111.0 |111.0 |CLT    |2016-04-01|1.0    |NY     |2016-04-08|39.0  |2.0    |1.0  |20160401|null    |null |G      |O      |null   |M      |1977.0 |06292016|M     |null  |AA     |5.5434929033E10|00787|WT      |\n",
      "|4949.0|2016.0|4.0   |111.0 |111.0 |DET    |2016-04-01|1.0    |CO     |2016-04-15|65.0  |2.0    |1.0  |20160401|null    |null |G      |O      |null   |M      |1951.0 |06292016|F     |null  |DL     |5.5421236933E10|00099|WT      |\n",
      "|5202.0|2016.0|4.0   |111.0 |111.0 |NEW    |2016-04-01|1.0    |NY     |2016-04-06|36.0  |2.0    |1.0  |20160401|null    |null |G      |O      |null   |M      |1980.0 |06292016|M     |null  |UA     |5.5413995133E10|00056|WT      |\n",
      "|5212.0|2016.0|4.0   |111.0 |111.0 |NEW    |2016-04-01|1.0    |NY     |2016-04-06|7.0   |2.0    |1.0  |20160401|null    |null |G      |O      |null   |M      |2009.0 |06292016|F     |null  |UA     |5.5414080433E10|00056|WT      |\n",
      "|5238.0|2016.0|4.0   |111.0 |111.0 |NEW    |2016-04-01|1.0    |NY     |2016-04-07|41.0  |2.0    |1.0  |20160401|null    |null |G      |O      |null   |M      |1975.0 |06292016|F     |null  |UA     |5.5413602933E10|00056|WT      |\n",
      "|5387.0|2016.0|4.0   |111.0 |111.0 |NEW    |2016-04-01|1.0    |NY     |2016-04-09|30.0  |2.0    |1.0  |20160401|null    |null |G      |O      |null   |M      |1986.0 |06292016|F     |null  |LX     |5.5458596533E10|00018|WT      |\n",
      "+------+------+------+------+------+-------+----------+-------+-------+----------+------+-------+-----+--------+--------+-----+-------+-------+-------+-------+-------+--------+------+------+-------+---------------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i94_df_cleanup = cleanup.drop_empty_columns(i94_df,[\"arrdate\",\"i94addr\",\"visatype\",\"biryear\",\"gender\",\"depdate\"])\n",
    "i94_df_cleanup = cleanup.drop_duplicate_rows(i94_df_cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping missing data...\n",
      "+----------------+--------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+---------------------------------+------+\n",
      "|City            |State         |Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|Race                             |Count |\n",
      "+----------------+--------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+---------------------------------+------+\n",
      "|Silver Spring   |Maryland      |33.8      |40601          |41862            |82463           |1562              |30908       |2.6                   |MD        |Hispanic or Latino               |25924 |\n",
      "|Quincy          |Massachusetts |41.0      |44129          |49500            |93629           |4147              |32935       |2.39                  |MA        |White                            |58723 |\n",
      "|Hoover          |Alabama       |38.5      |38040          |46799            |84839           |4819              |8229        |2.58                  |AL        |Asian                            |4759  |\n",
      "|Rancho Cucamonga|California    |34.5      |88127          |87105            |175232          |5821              |33878       |3.18                  |CA        |Black or African-American        |24437 |\n",
      "|Newark          |New Jersey    |34.6      |138040         |143873           |281913          |5829              |86253       |2.73                  |NJ        |White                            |76402 |\n",
      "|Peoria          |Illinois      |33.1      |56229          |62432            |118661          |6634              |7517        |2.4                   |IL        |American Indian and Alaska Native|1343  |\n",
      "|Avondale        |Arizona       |29.1      |38712          |41971            |80683           |4815              |8355        |3.18                  |AZ        |Black or African-American        |11592 |\n",
      "|West Covina     |California    |39.8      |51629          |56860            |108489          |3800              |37038       |3.56                  |CA        |Asian                            |32716 |\n",
      "|O'Fallon        |Missouri      |36.0      |41762          |43270            |85032           |5783              |3269        |2.77                  |MO        |Hispanic or Latino               |2583  |\n",
      "|High Point      |North Carolina|35.5      |51751          |58077            |109828          |5204              |16315       |2.65                  |NC        |Asian                            |11060 |\n",
      "|Folsom          |California    |40.9      |41051          |35317            |76368           |4187              |13234       |2.62                  |CA        |Hispanic or Latino               |5822  |\n",
      "|Folsom          |California    |40.9      |41051          |35317            |76368           |4187              |13234       |2.62                  |CA        |American Indian and Alaska Native|998   |\n",
      "|Philadelphia    |Pennsylvania  |34.1      |741270         |826172           |1567442         |61995             |205339      |2.61                  |PA        |Asian                            |122721|\n",
      "|Wichita         |Kansas        |34.6      |192354         |197601           |389955          |23978             |40270       |2.56                  |KS        |Hispanic or Latino               |65162 |\n",
      "|Wichita         |Kansas        |34.6      |192354         |197601           |389955          |23978             |40270       |2.56                  |KS        |American Indian and Alaska Native|8791  |\n",
      "|Fort Myers      |Florida       |37.3      |36850          |37165            |74015           |4312              |15365       |2.45                  |FL        |White                            |50169 |\n",
      "|Pittsburgh      |Pennsylvania  |32.9      |149690         |154695           |304385          |17728             |28187       |2.13                  |PA        |White                            |208863|\n",
      "|Laredo          |Texas         |28.8      |124305         |131484           |255789          |4921              |68427       |3.66                  |TX        |American Indian and Alaska Native|1253  |\n",
      "|Berkeley        |California    |32.5      |60142          |60829            |120971          |3736              |25000       |2.35                  |CA        |Asian                            |27089 |\n",
      "|Santa Clara     |California    |35.2      |63278          |62938            |126216          |4426              |52281       |2.75                  |CA        |White                            |55847 |\n",
      "+----------------+--------------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+---------------------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "demographics_df_cleanup = cleanup.drop_empty_columns(demographics_df,[\"city\",\"state\"])\n",
    "demographics_df_cleanup = cleanup.drop_duplicate_rows(demographics_df_cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping missing data...\n",
      "+-------------------+-------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|dt                 |AverageTemperature |AverageTemperatureUncertainty|City |Country|Latitude|Longitude|\n",
      "+-------------------+-------------------+-----------------------------+-----+-------+--------+---------+\n",
      "|1743-11-01 00:00:00|6.068              |1.7369999999999999           |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1744-04-01 00:00:00|5.7879999999999985 |3.6239999999999997           |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1744-05-01 00:00:00|10.644             |1.2830000000000001           |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1744-06-01 00:00:00|14.050999999999998 |1.347                        |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1744-07-01 00:00:00|16.082             |1.396                        |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1744-09-01 00:00:00|12.780999999999999 |1.454                        |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1744-10-01 00:00:00|7.95               |1.63                         |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1744-11-01 00:00:00|4.638999999999999  |1.3019999999999998           |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1744-12-01 00:00:00|0.12199999999999987|1.756                        |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1745-01-01 00:00:00|-1.3330000000000002|1.642                        |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1745-02-01 00:00:00|-2.732             |1.358                        |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1745-03-01 00:00:00|0.129              |1.088                        |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1745-04-01 00:00:00|4.042              |1.138                        |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1750-01-01 00:00:00|1.699              |1.013                        |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1750-02-01 00:00:00|3.9610000000000003 |2.3609999999999998           |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1750-03-01 00:00:00|5.182              |3.48                         |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1750-04-01 00:00:00|7.197              |0.732                        |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1750-05-01 00:00:00|10.634             |1.351                        |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1750-06-01 00:00:00|14.913             |1.181                        |Århus|Denmark|57.05N  |10.33E   |\n",
      "|1750-07-01 00:00:00|17.831             |1.22                         |Århus|Denmark|57.05N  |10.33E   |\n",
      "+-------------------+-------------------+-----------------------------+-----+-------+--------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temperature_df_cleanup = cleanup.drop_empty_columns(temperature_df,[\"dt\",\"AverageTemperature\"])\n",
    "temperature_df_cleanup = cleanup.drop_duplicate_rows(temperature_df_cleanup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, City: string, State: string, Median Age: string, Male Population: string, Female Population: string, Total Population: string, Number of Veterans: string, Foreign-born: string, Average Household Size: string, State Code: string, Race: string, Count: string]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics_df_cleanup.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maple Grove</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>38.6</td>\n",
       "      <td>31780</td>\n",
       "      <td>36601</td>\n",
       "      <td>68381</td>\n",
       "      <td>2943</td>\n",
       "      <td>7645</td>\n",
       "      <td>2.64</td>\n",
       "      <td>MN</td>\n",
       "      <td>White</td>\n",
       "      <td>59683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Concord</td>\n",
       "      <td>California</td>\n",
       "      <td>39.6</td>\n",
       "      <td>62310</td>\n",
       "      <td>66358</td>\n",
       "      <td>128668</td>\n",
       "      <td>6287</td>\n",
       "      <td>37428</td>\n",
       "      <td>2.72</td>\n",
       "      <td>CA</td>\n",
       "      <td>White</td>\n",
       "      <td>92575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Highlands Ranch</td>\n",
       "      <td>Colorado</td>\n",
       "      <td>39.6</td>\n",
       "      <td>49186</td>\n",
       "      <td>53281</td>\n",
       "      <td>102467</td>\n",
       "      <td>4840</td>\n",
       "      <td>8827</td>\n",
       "      <td>2.72</td>\n",
       "      <td>CO</td>\n",
       "      <td>Asian</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Asheville</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>37.9</td>\n",
       "      <td>42100</td>\n",
       "      <td>46407</td>\n",
       "      <td>88507</td>\n",
       "      <td>4973</td>\n",
       "      <td>6630</td>\n",
       "      <td>2.18</td>\n",
       "      <td>NC</td>\n",
       "      <td>American Indian and Alaska Native</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Westland</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>39.9</td>\n",
       "      <td>37742</td>\n",
       "      <td>44253</td>\n",
       "      <td>81995</td>\n",
       "      <td>4756</td>\n",
       "      <td>6429</td>\n",
       "      <td>2.41</td>\n",
       "      <td>MI</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>16422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wichita Falls</td>\n",
       "      <td>Texas</td>\n",
       "      <td>34.0</td>\n",
       "      <td>55775</td>\n",
       "      <td>48934</td>\n",
       "      <td>104709</td>\n",
       "      <td>7800</td>\n",
       "      <td>9855</td>\n",
       "      <td>2.41</td>\n",
       "      <td>TX</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>23061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Clovis</td>\n",
       "      <td>California</td>\n",
       "      <td>37.8</td>\n",
       "      <td>52392</td>\n",
       "      <td>51780</td>\n",
       "      <td>104172</td>\n",
       "      <td>6173</td>\n",
       "      <td>13409</td>\n",
       "      <td>2.76</td>\n",
       "      <td>CA</td>\n",
       "      <td>White</td>\n",
       "      <td>78029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Waldorf</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.6</td>\n",
       "      <td>35640</td>\n",
       "      <td>39872</td>\n",
       "      <td>75512</td>\n",
       "      <td>6932</td>\n",
       "      <td>5954</td>\n",
       "      <td>2.69</td>\n",
       "      <td>MD</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Schaumburg</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>36.9</td>\n",
       "      <td>35971</td>\n",
       "      <td>39840</td>\n",
       "      <td>75811</td>\n",
       "      <td>2019</td>\n",
       "      <td>24614</td>\n",
       "      <td>2.72</td>\n",
       "      <td>IL</td>\n",
       "      <td>White</td>\n",
       "      <td>43688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Winston-Salem</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>34.7</td>\n",
       "      <td>112520</td>\n",
       "      <td>128712</td>\n",
       "      <td>241232</td>\n",
       "      <td>14521</td>\n",
       "      <td>24302</td>\n",
       "      <td>2.47</td>\n",
       "      <td>NC</td>\n",
       "      <td>White</td>\n",
       "      <td>139301</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              City           State  Median Age  Male Population  \\\n",
       "0      Maple Grove       Minnesota        38.6            31780   \n",
       "1          Concord      California        39.6            62310   \n",
       "2  Highlands Ranch        Colorado        39.6            49186   \n",
       "3        Asheville  North Carolina        37.9            42100   \n",
       "4         Westland        Michigan        39.9            37742   \n",
       "5    Wichita Falls           Texas        34.0            55775   \n",
       "6           Clovis      California        37.8            52392   \n",
       "7          Waldorf        Maryland        33.6            35640   \n",
       "8       Schaumburg        Illinois        36.9            35971   \n",
       "9    Winston-Salem  North Carolina        34.7           112520   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0              36601             68381                2943          7645   \n",
       "1              66358            128668                6287         37428   \n",
       "2              53281            102467                4840          8827   \n",
       "3              46407             88507                4973          6630   \n",
       "4              44253             81995                4756          6429   \n",
       "5              48934            104709                7800          9855   \n",
       "6              51780            104172                6173         13409   \n",
       "7              39872             75512                6932          5954   \n",
       "8              39840             75811                2019         24614   \n",
       "9             128712            241232               14521         24302   \n",
       "\n",
       "   Average Household Size State Code                               Race  \\\n",
       "0                    2.64         MN                              White   \n",
       "1                    2.72         CA                              White   \n",
       "2                    2.72         CO                              Asian   \n",
       "3                    2.18         NC  American Indian and Alaska Native   \n",
       "4                    2.41         MI          Black or African-American   \n",
       "5                    2.41         TX                 Hispanic or Latino   \n",
       "6                    2.76         CA                              White   \n",
       "7                    2.69         MD                              Asian   \n",
       "8                    2.72         IL                              White   \n",
       "9                    2.47         NC                              White   \n",
       "\n",
       "    Count  \n",
       "0   59683  \n",
       "1   92575  \n",
       "2    5650  \n",
       "3     496  \n",
       "4   16422  \n",
       "5   23061  \n",
       "6   78029  \n",
       "7    4100  \n",
       "8   43688  \n",
       "9  139301  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics_df_cleanup.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2891"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographics_df_cleanup.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1850-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bontang</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0.80N</td>\n",
       "      <td>118.13E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1859-05-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bontang</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0.80N</td>\n",
       "      <td>118.13E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1862-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bontang</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0.80N</td>\n",
       "      <td>118.13E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1863-09-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Butembo</td>\n",
       "      <td>Congo (Democratic Republic Of The)</td>\n",
       "      <td>0.80N</td>\n",
       "      <td>29.73E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1864-07-01</td>\n",
       "      <td>20.314</td>\n",
       "      <td>1.248</td>\n",
       "      <td>Butembo</td>\n",
       "      <td>Congo (Democratic Republic Of The)</td>\n",
       "      <td>0.80N</td>\n",
       "      <td>29.73E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1880-05-01</td>\n",
       "      <td>26.876</td>\n",
       "      <td>0.844</td>\n",
       "      <td>Bontang</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0.80N</td>\n",
       "      <td>118.13E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1886-04-01</td>\n",
       "      <td>20.908</td>\n",
       "      <td>1.257</td>\n",
       "      <td>Butembo</td>\n",
       "      <td>Congo (Democratic Republic Of The)</td>\n",
       "      <td>0.80N</td>\n",
       "      <td>29.73E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1887-05-01</td>\n",
       "      <td>20.622</td>\n",
       "      <td>1.140</td>\n",
       "      <td>Butembo</td>\n",
       "      <td>Congo (Democratic Republic Of The)</td>\n",
       "      <td>0.80N</td>\n",
       "      <td>29.73E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1887-09-01</td>\n",
       "      <td>20.435</td>\n",
       "      <td>1.215</td>\n",
       "      <td>Butembo</td>\n",
       "      <td>Congo (Democratic Republic Of The)</td>\n",
       "      <td>0.80N</td>\n",
       "      <td>29.73E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1900-03-01</td>\n",
       "      <td>25.904</td>\n",
       "      <td>1.290</td>\n",
       "      <td>Bitung</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>0.80N</td>\n",
       "      <td>124.55E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dt  AverageTemperature  AverageTemperatureUncertainty     City  \\\n",
       "0 1850-04-01                 NaN                            NaN  Bontang   \n",
       "1 1859-05-01                 NaN                            NaN  Bontang   \n",
       "2 1862-09-01                 NaN                            NaN  Bontang   \n",
       "3 1863-09-01                 NaN                            NaN  Butembo   \n",
       "4 1864-07-01              20.314                          1.248  Butembo   \n",
       "5 1880-05-01              26.876                          0.844  Bontang   \n",
       "6 1886-04-01              20.908                          1.257  Butembo   \n",
       "7 1887-05-01              20.622                          1.140  Butembo   \n",
       "8 1887-09-01              20.435                          1.215  Butembo   \n",
       "9 1900-03-01              25.904                          1.290   Bitung   \n",
       "\n",
       "                              Country Latitude Longitude  \n",
       "0                           Indonesia    0.80N   118.13E  \n",
       "1                           Indonesia    0.80N   118.13E  \n",
       "2                           Indonesia    0.80N   118.13E  \n",
       "3  Congo (Democratic Republic Of The)    0.80N    29.73E  \n",
       "4  Congo (Democratic Republic Of The)    0.80N    29.73E  \n",
       "5                           Indonesia    0.80N   118.13E  \n",
       "6  Congo (Democratic Republic Of The)    0.80N    29.73E  \n",
       "7  Congo (Democratic Republic Of The)    0.80N    29.73E  \n",
       "8  Congo (Democratic Republic Of The)    0.80N    29.73E  \n",
       "9                           Indonesia    0.80N   124.55E  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df_cleanup.limit(20).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1848-06-01</td>\n",
       "      <td>24.970</td>\n",
       "      <td>1.799</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1892-05-01</td>\n",
       "      <td>21.656</td>\n",
       "      <td>0.501</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1917-02-01</td>\n",
       "      <td>8.004</td>\n",
       "      <td>0.518</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1937-04-01</td>\n",
       "      <td>17.291</td>\n",
       "      <td>0.307</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1942-09-01</td>\n",
       "      <td>21.529</td>\n",
       "      <td>0.319</td>\n",
       "      <td>Abilene</td>\n",
       "      <td>United States</td>\n",
       "      <td>32.95N</td>\n",
       "      <td>100.53W</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          dt  AverageTemperature  AverageTemperatureUncertainty     City  \\\n",
       "0 1848-06-01              24.970                          1.799  Abilene   \n",
       "1 1892-05-01              21.656                          0.501  Abilene   \n",
       "2 1917-02-01               8.004                          0.518  Abilene   \n",
       "3 1937-04-01              17.291                          0.307  Abilene   \n",
       "4 1942-09-01              21.529                          0.319  Abilene   \n",
       "\n",
       "         Country Latitude Longitude  \n",
       "0  United States   32.95N   100.53W  \n",
       "1  United States   32.95N   100.53W  \n",
       "2  United States   32.95N   100.53W  \n",
       "3  United States   32.95N   100.53W  \n",
       "4  United States   32.95N   100.53W  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df_cleanup_us = temperature_df_cleanup.filter(\"Country == 'United States'\")\n",
    "temperature_df_cleanup_us.limit(10).toPandas().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "687289"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df_cleanup_us.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, AverageTemperature: string, AverageTemperatureUncertainty: string, City: string, Country: string, Latitude: string, Longitude: string]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temperature_df_cleanup_us.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Convert date to datetime\n",
    "temperature_df_cleanup_us = temperature_df_cleanup_us.withColumn(\"convertedDate\",to_date(temperature_df.dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_temp_con' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-d72c757874de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_temp_con\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'convertedDate'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_temp_con' is not defined"
     ]
    }
   ],
   "source": [
    "df_temp_con.select(min('convertedDate')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def create_dim_table(label):\n",
    "    '''\n",
    "      Extract data from I94_SAS_file_content\n",
    "      :param : input_lable\n",
    "      :return :code,value   \n",
    "    '''\n",
    "    with open('I94_SAS_file_content.SAS') as file_content:\n",
    "            raw_labels = file_content.read()\n",
    "    labels = raw_labels[raw_labels.index(label):]\n",
    "    labels = labels[:labels.index(';')]\n",
    "    lines = labels.splitlines()\n",
    "    code_value_list = []\n",
    "    try:\n",
    "        code, value = line.split('=')\n",
    "        code = code.strip().strip(\"'\").strip('\"')\n",
    "        value = value.strip().strip(\"'\").strip('\"').strip()\n",
    "        code_value_list.append((code, value))\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    return code_value_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Immigration data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_df_cleanup.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_df_cleanup.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Filter valid ports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_sas_label_des_filename = \"I94_SAS_file_content.SAS\"\n",
    "with open(i94_sas_label_des_filename) as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "re_compiled = re.compile(r\"\\'(.*)\\'.*\\'(.*)\\'\")\n",
    "valid_ports = {}\n",
    "for line in lines[302:961]:\n",
    "    results = re_compiled.search(line)\n",
    "    valid_ports[results.group(1)] = results.group(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### valid states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "valid_states = demographics_df.toPandas()[\"State Code\"].unique().tolist()\n",
    "type(valid_states)\n",
    "print(valid_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#valid_states = demographics_df.select('State Code').distinct().collect()\n",
    "#print(valid_states.toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "demographics_df_cleanup.select('State Code').distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "Following star scheam is designed , it is very simple and powerful.\n",
    "\n",
    "\n",
    "### staging_i94\n",
    "    id\n",
    "    date\n",
    "    city_code\n",
    "    state_code\n",
    "    age\n",
    "    gender\n",
    "    visa_type\n",
    "    count\n",
    "\n",
    "### staging_temperature\n",
    "    year\n",
    "    month\n",
    "    city_code\n",
    "    city_name\n",
    "    avg_temp\n",
    "    lat\n",
    "    long\n",
    "\n",
    "### staging_demographics\n",
    "    city_code\n",
    "    state_code\n",
    "    city_name\n",
    "    medianAge\n",
    "    male_pop\n",
    "    female_pop\n",
    "    veterans\n",
    "    foreign_born\n",
    "    total_pop\n",
    "### Dimension Tables\n",
    "### dim_immigration\n",
    "    id\n",
    "    gender\n",
    "    age\n",
    "    visa_type\n",
    "\n",
    "#### dim_demographics\n",
    "    city_code\n",
    "    state_code\n",
    "    city_name\n",
    "    medianAge\n",
    "    male_pop\n",
    "    female_pop\n",
    "    veterans\n",
    "    foreign_born\n",
    "    total_pop\n",
    "    lat\n",
    "    long\n",
    "### dim_monthly_city_temp\n",
    "    city_code\n",
    "    year\n",
    "    month\n",
    "    avg_temp\n",
    "\n",
    "### dim_time\n",
    "    date\n",
    "    dayofweek\n",
    "    weekofyear\n",
    "    month\n",
    "### Fact Table\n",
    "### immigrations\n",
    "    id\n",
    "    state_code\n",
    "    city_code\n",
    "    date\n",
    "    count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Refer tables.png file to get schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 3.2 Mapping Out Data Pipelines\n",
    "\n",
    "### Steps necessary to pipeline the data into the chosen data model\n",
    "\n",
    "1. Clean the data on nulls, data types, duplicates, etc\n",
    "2. Load staging tables for stag_i94_df, stag_temp_df and stag_demo_df\n",
    "3. Create dimension tables for imm_df, city_df, monthly_city_temp_df and time_df\n",
    "4. Create fact table immigration_df with information on immigration count, mapping id in imm_df, city_code in city_df and monthly_city_temp_df and date in time_df to make sure  referential integrity\n",
    "5. Save processed dimension and fact tables in parquet for downstream query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### clean immigraton data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# create a function\n",
    "@udf(StringType())\n",
    "def state_validation(st):\n",
    "    print(st)\n",
    "    if st in valid_states:\n",
    "        return  st\n",
    "    return 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# convert date\n",
    "@udf(StringType())\n",
    "def conv_date(x):\n",
    "    if x:\n",
    "        return (datetime(1960,1,1).date() + timedelta(x)).isoformat()\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove any missing values ( any null value from columns i94port, i94addr, gender)\n",
    "i94_c_d = i94_df.dropna(how=\"any\", subset=[\"i94port\",\"i94addr\",\"gender\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_c_d.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_c_d = i94_c_d.withColumn(\"i94addr\", state_validation(i94_c_d.i94addr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_c_d= i94_c_d.withColumn(\"arrdate\", conv_date(i94_c_d.arrdate))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_c_d = i94_c_d.filter(i94_c_d.i94addr != 'None')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_c_d.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "### staging i94 df table\n",
    "i94_s_t = i94_c_d.select(\n",
    "col(\"cicid\").alias(\"id\"),\n",
    "    col(\"arrdate\").alias(\"date\"),\n",
    "    col(\"i94addr\").alias(\"city_code\"),\n",
    "    col(\"i94bir\").alias(\"age\"),\n",
    "    col(\"gender\").alias(\"gender\"),\n",
    "    col(\"i94visa\").alias(\"visa_type\"), \"count\").drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "i94_s_t.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Create udf to map city full name to city port\n",
    "@udf(StringType())\n",
    "def city_to_port(city):\n",
    "    for key in valid_ports:\n",
    "        if city.lower() in valid_ports[key].lower():\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Temperature clean up\n",
    "df_temp_con.filter(df_temp_con[\"Country\"] == \"United States\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Remove any missing values from temperature ( any null value from columns i94port)\n",
    "df_temp_con_clean_up = df_temp_con.dropna(how=\"any\", subset=[\"City\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cleaned_temp_df = df_temp_con.\\\n",
    "withColumn(\"year\", year(df_temp_con['dt'])) \\\n",
    "    .withColumn(\"month\", month(df_temp_con[\"dt\"])) \\\n",
    "    .withColumn(\"i94port\", city_to_port(df_temp_con[\"City\"])) \\\n",
    "    .withColumn(\"AverageTemperature\", col(\"AverageTemperature\").cast(\"float\")) \\\n",
    "    .dropna(how='any', subset=[\"i94port\"])\n",
    "\n",
    "cleaned_temp_df.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#consider data only from 2013 year\n",
    "cleaned_temp_df = cleaned_temp_df.filter(cleaned_temp_df[\"year\"] == 2013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "stag_temp_df = cleaned_temp_df.select(col(\"year\"), col(\"month\"), col(\"i94port\").alias(\"city_code\"),\n",
    "                                         round(col(\"AverageTemperature\"), 1).alias(\"avg_temp\"),\n",
    "                                         col(\"Latitude\").alias(\"lat\"), col(\"Longitude\").alias(\"long\")).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(stag_temp_df.count())\n",
    "stag_temp_df.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "stag_temp_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "c_demo_df = demographics_df.withColumn(\"medianAge\", demographics_df['Median Age']) \\\n",
    "    .withColumn(\"male_pop\", (demographics_df['Male Population'] / demographics_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"female_pop\", (demographics_df['Female Population'] / demographics_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"veterans\", (demographics_df['Number of Veterans'] / demographics_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"foreign_born\", (demographics_df['Foreign-born'] / demographics_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"race\", (demographics_df['Count'] / demographics_df['Total Population']) * 100) \\\n",
    "    .withColumn(\"city_code\", city_to_port(demographics_df[\"City\"])) \\\n",
    "    .dropna(how='any', subset=[\"city_code\"])\n",
    "\n",
    "c_demo_df.limit(10).toPandas().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "cleaned_demo_df = c_demo_df.select(col(\"City\").alias(\"city_name\"), \\\n",
    "                                   col(\"State Code\").alias(\"state_code\"), \n",
    "                                  \"medianAge\", \"male_pop\", \"female_pop\",\"veterans\", \\\n",
    "                                   \"foreign_born\", \\\n",
    "                                   col(\"Total Population\").alias(\"total_pop\"), \\\n",
    "                                   #col(\"Race\").alias(\"race\"), \\\n",
    "                                   \"race\").drop_duplicates()\n",
    "\n",
    "cleaned_demo_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "p_demo_df = cleaned_demo_df.groupBy(\"city_name\", \"state_code\", \"medianAge\", \"male_pop\",\n",
    "                                        \"female_pop\",\"veterans\", \"foreign_born\", \"total_pop\").pivot(\"Race\").avg(\"race\")\n",
    "\n",
    "p_demo_df = p_demo_df.withColumn(\"city_code\", city_to_port(p_demo_df[\"city_name\"])) \\\n",
    "    .dropna(how='any', subset=[\"city_code\"])\n",
    "\n",
    "p_demo_df.limit(10).toPandas().head(10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "stag_demo_df = p_demo_df.select(\"city_code\", \"state_code\", \"city_name\", \"medianAge\", \\\n",
    "                                    round(col(\"male_pop\"), 1).alias(\"male_pop\"),\\\n",
    "                                    round(col(\"female_pop\"), 1).alias(\"female_pop\"),\\\n",
    "                                    round(col(\"veterans\"), 1).alias(\"veterans\"),\\\n",
    "                                    round(col(\"veterans\"), 1).alias(\"foreign_born\"), \"total_pop\")\n",
    "stag_demo_df.limit(10).toPandas()\n",
    "stag_demo_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "im_df = i94_s_t.select(\"id\", \"gender\", \"age\", \"visa_type\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#im_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "c_df = stag_demo_df.join(stag_temp_df, \"city_code\") \\\n",
    "    .select(\"city_code\", \"state_code\", \"city_name\", \"medianAge\", \"male_pop\", \"female_pop\", \"veterans\",\n",
    "           \"foreign_born\", \"total_pop\", \"lat\", \"long\").drop_duplicates()\n",
    "c_df.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "m_df = stag_temp_df.select(\"city_code\", \"year\", \"month\", \"avg_temp\").drop_duplicates()\n",
    "m_df.limit(10).toPandas().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#m_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "time_df = i94_s_t.withColumn(\"dayofweek\", dayofweek(\"date\"))\\\n",
    "                .withColumn(\"weekofyear\", weekofyear(\"date\"))\\\n",
    "                .withColumn(\"month\", month(\"date\"))\n",
    "                        \n",
    "time_df = time_df.select(\"date\", \"dayofweek\", \"weekofyear\", \"month\").drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "#time_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "time_df.limit(5).toPandas().head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Write to dimension tables\n",
    "i94_df_cleanup.write.mode(\"overwrite\").partitionBy(\"gender\", \"age\").parquet(\"immigrants\")\n",
    "c_df.write.mode(\"overwrite\").partitionBy(\"state_code\").parquet(\"cities\")\n",
    "m_df.write.mode(\"overwrite\").parquet(\"monthly_city_temperatues\")\n",
    "time_df.write.mode(\"overwrite\").parquet(\"time\")\n",
    "\n",
    "# Write to  fact table\n",
    "immigration_df.write.mode(\"overwrite\").partitionBy(\"state_code\", \"city_code\").parquet(\"immigration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### 4.2 Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_parquets():\n",
    "    # load immigration parquest file, create view and query\n",
    "    read_im_df = pySparkSession.read.parquet(\"immigrants/\")\n",
    "    immigration = read_im_df.createOrReplaceTempView(\"immigrants\")\n",
    "    table_im_df = pySparkSession.sql(\"select * from immigrants limit 10\");\n",
    "    cleanup.data_quality_check(table_im_df, \"immigrants\")\n",
    "    table_im_df.printSchema()\n",
    "    # load cities parquest file create view and query\n",
    "    table_c_df = pySparkSession.read.parquet(\"cities/\")\n",
    "    cities = table_c_df.createOrReplaceTempView(\"cities\")\n",
    "    citi_table = pySparkSession.sql(\"select * from cities limit 10\");\n",
    "    cleanup.data_quality_check(citi_table, \"cities\")\n",
    "    table_m_df = pySparkSession.read.parquet(\"monthly_city_temperatues/\")\n",
    "    city_temperatures = table_m_df.createOrReplaceTempView(\"city_temperatures\")\n",
    "    city_temparature_table = pySparkSession.sql(\"select * from city_temperatures limit 10\");\n",
    "    cleanup.data_quality_check(city_temparature_table, \"city_temperatures\")\n",
    "    table_time = pySparkSession.read.parquet(\"time/\")\n",
    "    time = table_time.createOrReplaceTempView(\"time\")\n",
    "    time_table = pySparkSession.sql(\"select * from time limit 10\");\n",
    "    cleanup.data_quality_check(time_table, \"time\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "\n",
    "### Dimension Tables\n",
    "\n",
    "### city_df\n",
    "    city_code: represents city port code\n",
    "    state_code: represents state code of the city\n",
    "    city_name: represents name of the city\n",
    "    medianAge: represents median age of the city\n",
    "    male_pop: represents city male population in %\n",
    "    female_pop: represents city's female population in %\n",
    "    veterans: represents city's veteran population in %\n",
    "    foreign_born: represents city's foreign born population in %\n",
    "    total_pop: represents city's total population\n",
    "    lat: represents latitude of the city\n",
    "    long: represents longitude of the city\n",
    "\t\n",
    "### imm_df\n",
    "    id: represents id of immigrant\n",
    "    gender: represents gender of immigrant\n",
    "    age: represents age of immigrant\n",
    "    visa_type: represents immigrant's visa type\n",
    "\n",
    "### city_df\n",
    "    city_code: represents city port code\n",
    "    state_code: represents state code of the city\n",
    "    city_name: represents name of the city\n",
    "    medianAge: represents median age of the city\n",
    "    male_pop: represents city's male population in %\n",
    "    female_pop: represents city's female population in %\n",
    "    veterans: represents city's veteran population in %\n",
    "    foreign_born: represents city's foreign born population in %\n",
    "    total_pop: represents city's total population\n",
    "    lat: represents latitude of the city\n",
    "    long: represents longitude of the city\n",
    "\n",
    "### monthly_city_temp_df\n",
    "    city_code: represents city port code\n",
    "    year: represents year\n",
    "    month: represents month \n",
    "    avg_temp: represents average temperature in city for given month\n",
    "\n",
    "### time_df\n",
    "    date: represents date\n",
    "    dayofweek: represents day of the week\n",
    "    weekofyear: represents week of year\n",
    "    month: represents month\n",
    "### Fact Table\n",
    "### immigration_df\n",
    "    id: represents id\n",
    "    state_code: represents state code of arrival city\n",
    "    city_code: represents city port code of arrival city\n",
    "    date: represents date of arrival\n",
    "    count: represents count of immigrant's entries into the US"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "\n",
    "\n",
    "Apache Spark used  because of ability to process large set of data along with apis to read data and its convenient dataframe manipulation functions\n",
    "\n",
    "* Propose how often the data should be updated and why.\n",
    "\n",
    "The immigration (i94) data set and relevant data can be updated montly as this is report can fetch mothly/seasonally. \n",
    "\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x: An Amazon EMR cluster can be useda with Apache Spark installed to process the increase in data easily prior to being stored on S3.S3 have capabiliity to auto scale at any speed. \n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day: We can define airflow to run job every day at 7am on dela to make process more effective. \n",
    " * The database needed to be accessed by 100+ people.\n",
    "  We can use redshift to store staging, dimention and fact tables as it was cluster and improves performance, multiple people can case at any point of time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# read from dimension tables\n",
    "read_im_df = pySparkSession.read.parquet(\"immigrants/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "table_im_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "def execute_quries():\n",
    "    # visa's count based on male and female\n",
    "    visa_type_count_male = pySparkSession.sql(\"select count(*),gender from immigrants  group by gender limit 10\");\n",
    "    visa_type_count_male.show()\n",
    "   \n",
    "    # Avg temperature per month per city\n",
    "    city_temparature_table = pySparkSession.sql(\"select * from city_temperatures where year = '2016'\");\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "execute_quries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    " # Avg temperature in year 2013 per month per city\n",
    "city_temparature_table = pySparkSession.sql(\"select * from city_temperatures where year = 2013\");\n",
    "city_temparature_table.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    " # Avg temperature in year 2013 per month per city\n",
    "city_temparature_table = pySparkSession.sql(\"select * from city_temperatures where year = 2013\");\n",
    "city_temparature_table.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    " #Most popular cities\n",
    "popular_cities = pySparkSession.sql(\"select total_pop,city_code from immigrants order by total_pop\");\n",
    "popular_cities.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "check_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Most popular cities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "citi_table.printSchema()\n",
    "city_temparature_table.printSchema()\n",
    "time_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
